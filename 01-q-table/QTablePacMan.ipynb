{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVIU8pUwBydWF4v68r/Nbk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install gymnasium"],"metadata":{"id":"KJUp6QBRY-Qd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from time import sleep\n","import numpy as np\n","from IPython.display import clear_output\n","import gymnasium as gym\n","from gymnasium.envs.registration import register"],"metadata":{"id":"K_GLg7lbayhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Give colab access to your google drive:\n","from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"7PWN1PkGe66q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Change current directory to folder with MiniPacManGym.py\n","%cd /gdrive/MyDrive/CS181V/Qtable"],"metadata":{"id":"1SCX1d90YjOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import MiniPacMan environment class definition\n","from MiniPacManGym import MiniPacManEnv"],"metadata":{"id":"GCa5TYdVWL2y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Register MiniPacMan in your gymnasium environments\n","register(\n","    id=\"MiniPacMan-v0\",\n","    entry_point=MiniPacManEnv,\n","    max_episode_steps=20\n",")"],"metadata":{"id":"TcY1Q97RRy6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a MiniPacMan gymnasium environment\n","env = gym.make(\"MiniPacMan-v0\", render_mode=\"human\", frozen_ghost=True)"],"metadata":{"id":"k7hwnC7Ob9VJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set hyperparams -- feel free to play with these!\n","gamma=0.999\n","alpha=0.9\n","num_episodes=10000\n","\n","#initialize epsilon, Q\n","epsilon=1\n","Q=np.zeros((6,6,4)) #First two coordinates encode state, last encodes action\n","\n","for e in range(num_episodes):\n","  new_obs,info=env.reset()\n","  new_pos=np.argwhere(new_obs==1)[0] #current pacman position\n","  done=False\n","  truncated=False\n","  steps=0\n","\n","  while not done and not truncated: #Loop for one episode\n","    obs=new_obs\n","    pos=new_pos\n","\n","    #choose action\n","    t=np.random.random()\n","    if t>epsilon:\n","      action=#YOUR CODE HERE #exploitation\n","    else:\n","      action=#YOUR CODE HERE #exploration\n","\n","    #take a step:\n","    new_obs,reward, done, truncated, info=env.step(action)\n","    steps+=1\n","    new_pos=np.argwhere(new_obs==1)[0] #next pacman position\n","\n","    #Q-table update rule:\n","    Q[pos[0],pos[1],action]=#YOUR CODE HERE\n","\n","  #reduce episilon if its not too low\n","  #Should be close to zero after 50 - 60% of episodes, and then level off\n","  epsilon=#YOUR CODE HERE\n","\n","  #periodic reporting:\n","  if e%100==0:\n","    print(f'episode: {e}, steps: {steps}, epislon: {epsilon}, win: {reward==10}')\n"],"metadata":{"id":"0fe-YvvwKpAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Run this code cell to see your trained agent in action!\n","\n","obs, info = env.reset()\n","done = False\n","truncated = False\n","\n","while not done and not truncated:\n","    env.render()\n","    pos=#YOUR CODE HERE   #pacman position\n","    action=#YOUR CODE HERE\n","    obs, reward, done, truncated, info = env.step(action)\n","    sleep(1)\n","    clear_output(wait=True)\n","\n","env.close()"],"metadata":{"id":"0SXyI97eNx6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VZjO1S_URYs2"},"execution_count":null,"outputs":[]}]}